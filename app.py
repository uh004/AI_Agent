# app.py
import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

import gradio as gr

from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, START, END

# ----- í”„ë¡œì íŠ¸ ë‚´ë¶€ ëª¨ë“ˆ -----
from models.state_types import InterviewState
from core.evaluator import evaluate_answer
from core.next_step import decide_next_step, change_strategy, route_next
from core.summarizer import summarize_interview
from core.generator import generate_question
from core.question_strategy import preProcessing_Interview

# ========== LLM ==========
llm = ChatOpenAI(model="gpt-4.1-mini")

def update_current_answer(state: InterviewState, user_answer: str) -> InterviewState:
    return {**state, "current_answer": user_answer.strip()}


# ========== LangGraph êµ¬ì„± ==========
# ë‚´ë¶€ ë…¸ë“œ: ì‚¬ìš©ì ë‹µë³€ì„ stateì— ë°˜ì˜ (ì„ì‹œ í‚¤ 'incoming_answer' ì‚¬ìš©)??
def _update_answer_node(state: InterviewState) -> InterviewState:
    user_answer = state.get("current_answer", "")
    new_state = update_current_answer(state, user_answer)
    if "current_answer" in new_state:
        new_state.pop("current_answer")
    return new_state



# ê·¸ë˜í”„ ì •ì˜ ì‹œì‘
builder = StateGraph(InterviewState)

# ë…¸ë“œ ì¶”ê°€
builder.add_node("update_answer", _update_answer_node)
builder.add_node("evaluate", evaluate_answer)
builder.add_node("decide", decide_next_step)
builder.add_node("generate", generate_question)
builder.add_node("change_strategy", change_strategy)
builder.add_node("summarize", summarize_interview)

# ë…¸ë“œ ì—°ê²°
builder.set_entry_point("update_answer")
builder.add_edge("update_answer", "evaluate")
builder.add_edge("evaluate", "decide")
builder.add_conditional_edges(
    "decide",
    route_next,
    {
        "generate": "generate",
        "change_strategy" : "change_strategy",
        "summarize": "summarize",
    }
)
builder.add_edge("generate", END)
builder.add_edge("change_strategy", END)
builder.add_edge("summarize", END)

# ì»´íŒŒì¼
graph = builder.compile()



# ========== Gradio UI ==========
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” í•¨ìˆ˜
def initialize_state():
    return {
        "state": None,
        "interview_started": False,
        "interview_ended": False,
        "chat_history": []
    }

# íŒŒì¼ ì—…ë¡œë“œ í›„ ì¸í„°ë·° ì´ˆê¸°í™”
def upload_and_initialize(file_obj, session_state):
    if file_obj is None:
        return session_state, "íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."

    # GradioëŠ” file_obj.name ì´ íŒŒì¼ ê²½ë¡œì•¼
    file_path = file_obj.name

    # ì¸í„°ë·° ì‚¬ì „ ì²˜ë¦¬
    state = preProcessing_Interview(file_path)
    session_state["state"] = state
    session_state["interview_started"] = True

    # ì²« ì§ˆë¬¸ ì €ì¥
    first_question = state["current_question"]
    session_state["chat_history"].append(["ğŸ¤– AI ë©´ì ‘ê´€", first_question])

    return session_state, session_state["chat_history"]

# ë‹µë³€ ì²˜ë¦¬ ë° ë‹¤ìŒ ì§ˆë¬¸ ìƒì„±
def chat_interview(user_input, session_state):
    # (0) ì¸í„°ë·° ë¯¸ì‹œì‘ ì²˜ë¦¬
    if not session_state["interview_started"]:
        msg = "ë¨¼ì € ì´ë ¥ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ì¸í„°ë·°ë¥¼ ì‹œì‘í•˜ì„¸ìš”."
        session_state["chat_history"].append(["AI ë©´ì ‘ê´€", msg])
        return session_state, session_state["chat_history"], gr.update(value="")

    # (1) ì‚¬ìš©ì ë‹µë³€ ì €ì¥
    session_state["chat_history"].append(["ì§€ì›ì", user_input])
    state = update_current_answer(session_state["state"], user_input)

    # (2) í‰ê°€ â†’ ê²°ì • â†’ ë‹¤ìŒ í–‰ë™ (ë‹¨ê³„ë³„ ì‹¤í–‰)
    state = evaluate_answer(state)
    state = decide_next_step(state)

    next_step = state.get("next_step", "")

    if next_step == "generate":
        state = generate_question(state)
    elif next_step == "change_strategy":
        state = change_strategy(state)
    elif next_step == "summarize":
        state = summarize_interview(state)

    # (3) ìƒíƒœ ì €ì¥
    session_state["state"] = state

    # (4) ì¢…ë£Œ ì—¬ë¶€ íŒë‹¨
    if state.get("next_step") == "end":
        session_state["interview_ended"] = True
        final_report = state.get("final_report", "ì¸í„°ë·°ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        session_state["chat_history"].append(["AI ë©´ì ‘ê´€", final_report])
        return session_state, session_state["chat_history"], gr.update(value="")

    # (5) ë‹¤ìŒ ì§ˆë¬¸ ì œì‹œ
    next_question = state.get("current_question", "ë‹¤ìŒ ì§ˆë¬¸ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤...")
    session_state["chat_history"].append(["AI ë©´ì ‘ê´€", next_question])
    return session_state, session_state["chat_history"], gr.update(value="")

# Gradio ì¸í„°í˜ì´ìŠ¤ êµ¬ì„±(**ìˆ˜ì •**)

# í…Œë§ˆ ì„¤ì •
theme = gr.themes.Soft(
    primary_hue="blue",
    secondary_hue="gray",
    font=["Noto Sans KR", "sans-serif"],
).set(
    body_background_fill="#f8fafc",
    block_background_fill="white",
    input_background_fill="#f1f5f9",
    button_primary_background_fill="#3b82f6",
    button_primary_background_fill_hover="#2563eb",
)

with gr.Blocks(theme=theme, title="AI ë©´ì ‘ê´€") as demo:
    session_state = gr.State(initialize_state())

    # ì œëª©
    gr.Markdown(
        """
        <div style="text-align: center; padding: 32px 0 16px;">
            <h1 style="font-size: 2.6em; margin: 0; color: #1e40af; font-weight: 700;">
                AI ë©´ì ‘ê´€
            </h1>
            <p style="font-size: 1.1em; color: #4b5563; margin: 12px 0 0;">
                ì´ë ¥ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  KT AI/DX ì§ë¬´ ë©´ì ‘ì„ ê²½í—˜í•´ë³´ì„¸ìš”.
            </p>
        </div>
        """
    )

    # íŒŒì¼ ì—…ë¡œë“œ + ì‹œì‘
    with gr.Row():
        file_input = gr.File(
            label="ì´ë ¥ì„œ ì—…ë¡œë“œ (PDF ë˜ëŠ” DOCX)",
            file_types=[".pdf", ".docx"],
            type="filepath"
        )
        upload_btn = gr.Button(
            "ì¸í„°ë·° ì‹œì‘",
            variant="primary",
            size="lg"
        )

    # ìƒíƒœ í‘œì‹œ
    status_display = gr.Markdown("**ìƒíƒœ:** ì¤€ë¹„ ì¤‘", elem_id="status")

    # ì±„íŒ…ì°½ (ì•„ì´ì½˜ ìˆìŒ)
    chatbot = gr.Chatbot(
        height=520,
        show_label=False,
        avatar_images=(
            "https://img.icons8.com/color/48/000000/user-male-circle.png",  # ì§€ì›ì
            "https://img.icons8.com/emoji/48/000000/robot-emoji.png"        # AI
        ),
        render_markdown=True,
        bubble_full_width=False,
        latex_delimiters=[],
        elem_classes="chat"
    )

    # ì…ë ¥ì°½ (Enter ì „ìš©)
    user_input = gr.Textbox(
        show_label=False,
        placeholder="ë‹µë³€ì„ ì…ë ¥í•˜ê³  Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...",
        container=False
    )

    # === ë³´ê³ ì„œ ì „ìš© ì¹´ë“œ ì˜ì—­ (ìˆ¨ê¹€ â†’ ì¢…ë£Œ ì‹œ í‘œì‹œ) ===
    report_card = gr.HTML(visible=False)

    # === ì´ë²¤íŠ¸ ===
    def start_interview(file_obj, sess):
        if not file_obj:
            return sess, [["AI ë©´ì ‘ê´€", "ì´ë ¥ì„œë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."]], "**ìƒíƒœ:** íŒŒì¼ ì—†ìŒ", gr.update(visible=False)

        sess, _ = upload_and_initialize(file_obj, sess)
        first_q = sess["state"]["current_question"]
        chat = [["AI ë©´ì ‘ê´€", first_q]]
        sess["chat_history"] = chat
        sess["interview_started"] = True
        return sess, chat, "**ìƒíƒœ:** ë©´ì ‘ ì‹œì‘ë¨", gr.update(visible=False)

    upload_btn.click(
        start_interview,
        inputs=[file_input, session_state],
        outputs=[session_state, chatbot, status_display, report_card]
    )

    def respond(message, sess):
        if not sess.get("interview_started", False):
            return sess, sess["chat_history"] + [["AI ë©´ì ‘ê´€", "ì¸í„°ë·°ë¥¼ ë¨¼ì € ì‹œì‘í•´ì£¼ì„¸ìš”."]], "**ìƒíƒœ:** ëŒ€ê¸° ì¤‘", gr.update(visible=False)

        # sess["chat_history"].append(["ì§€ì›ì", message])
        sess, new_chat, _ = chat_interview(message, sess)

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        cur = sess["state"].get("current_strategy", "ì¤€ë¹„")
        status = f"**ìƒíƒœ:** {cur} ë©´ì ‘ ì¤‘"

        # === ì¸í„°ë·° ì¢…ë£Œ ì‹œ ===
        if sess["state"].get("next_step") == "end":
            status = "**ìƒíƒœ:** ì¸í„°ë·° ì¢…ë£Œ"
            report = sess["state"].get("final_report", "ì¸í„°ë·°ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

            # ë³´ê³ ì„œ ì¹´ë“œ ìƒì„± (HTML)
            report_html = f"""
            <div style="background:#f8fafc; border:1px solid #e2e8f0; border-radius:16px; padding:24px; margin-top:16px; box-shadow:0 4px 12px rgba(0,0,0,0.05);">
                <h2 style="margin:0 0 16px; color:#1e40af; font-size:1.5em;">AI ë©´ì ‘ í”¼ë“œë°± ë³´ê³ ì„œ</h2>
                <div style="white-space:pre-wrap; font-size:0.95em; line-height:1.6; color:#374151;">
                    {report.replace('============================================================', '').strip()}
                </div>
            </div>
            """
            report_card_update = gr.update(value=report_html, visible=True)
        else:
            report_card_update = gr.update(visible=False)

        sess["chat_history"] = new_chat
        return sess, new_chat, status, report_card_update

    user_input.submit(
        respond,
        inputs=[user_input, session_state],
        outputs=[session_state, chatbot, status_display, report_card]
    ).then(
        lambda: "", outputs=user_input
    )

# === CSS: ê¹”ë”í•œ ë§í’ì„  + ì¹´ë“œ ìŠ¤íƒ€ì¼ ===
demo.css = """
#status { text-align: center; font-size: 0.9em; color: #4b5563; margin: 8px 0; }
.chat .message {
    border-radius: 14px;
    padding: 11px 15px;
    margin: 6px 0;
    max-width: 82%;
    box-shadow: 0 1px 2px rgba(0,0,0,0.05);
}
.chat .message.user {
    background: #dbeafe;
    align-self: flex-end;
    border-bottom-right-radius: 4px;
}
.chat .message.bot {
    background: #f3f4f6;
    align-self: flex-start;
    border-bottom-left-radius: 4px;
}
"""

# === ì‹¤í–‰ ===
demo.launch(share=True)